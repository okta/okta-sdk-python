# The Okta software accompanied by this notice is provided pursuant to the following terms:
# Copyright Â© 2025-Present, Okta, Inc.
# Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the
# License.
# You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0.
# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS
# IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and limitations under the License.
# coding: utf-8

"""
Okta Admin Management

Allows customers to easily access the Okta Management APIs

The version of the OpenAPI document: 5.1.0
Contact: devex-public@okta.com
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501

from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from datetime import datetime
from importlib import import_module
from typing import Any, ClassVar, Dict, List, Union
from typing import Optional, Set
from typing import TYPE_CHECKING

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator

from okta.models.log_stream_links_self_and_lifecycle import (
    LogStreamLinksSelfAndLifecycle,
)
from okta.models.log_stream_type import LogStreamType

if TYPE_CHECKING:
    from okta.models.log_stream_aws import LogStreamAws
    from okta.models.log_stream_splunk import LogStreamSplunk


class LogStream(BaseModel):
    """
    LogStream
    """  # noqa: E501

    created: datetime = Field(
        description="Timestamp when the Log Stream object was created"
    )
    id: StrictStr = Field(description="Unique identifier for the Log Stream")
    last_updated: datetime = Field(
        description="Timestamp when the Log Stream object was last updated",
        alias="lastUpdated",
    )
    name: StrictStr = Field(description="Unique name for the Log Stream object")
    status: StrictStr = Field(description="Lifecycle status of the Log Stream object")
    type: LogStreamType
    links: LogStreamLinksSelfAndLifecycle = Field(alias="_links")
    __properties: ClassVar[List[str]] = [
        "created",
        "id",
        "lastUpdated",
        "name",
        "status",
        "type",
        "_links",
    ]

    @field_validator("status")
    def status_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(["ACTIVE", "INACTIVE"]):
            raise ValueError("must be one of enum values ('ACTIVE', 'INACTIVE')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    # JSON field name that stores the object type
    __discriminator_property_name: ClassVar[str] = "type"

    # discriminator mappings
    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
        "aws_eventbridge": "LogStreamAws",
        "splunk_cloud_logstreaming": "LogStreamSplunk",
    }

    @classmethod
    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
        """Returns the discriminator value (object type) of the data"""
        discriminator_value = obj[cls.__discriminator_property_name]
        if discriminator_value:
            return cls.__discriminator_value_class_map.get(discriminator_value)
        else:
            return None

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Union[LogStreamAws, LogStreamSplunk]]:
        """Create an instance of LogStream from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set(
            [
                "created",
                "id",
                "last_updated",
                "status",
            ]
        )

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of links
        if self.links:
            if not isinstance(self.links, dict):
                _dict["_links"] = self.links.to_dict()
            else:
                _dict["_links"] = self.links

        return _dict

    @classmethod
    def from_dict(
            cls, obj: Dict[str, Any]
    ) -> Optional[Union[LogStreamAws, LogStreamSplunk]]:
        """Create an instance of LogStream from a dict"""
        # look up the object type based on discriminator mapping
        object_type = cls.get_discriminator_value(obj)
        if object_type == "LogStreamAws":
            return import_module("okta.models.log_stream_aws").LogStreamAws.from_dict(
                obj
            )
        if object_type == "LogStreamSplunk":
            return import_module(
                "okta.models.log_stream_splunk"
            ).LogStreamSplunk.from_dict(obj)

        raise ValueError(
            "LogStream failed to lookup discriminator value from " +
            json.dumps(obj) +
            ". Discriminator property name: " +
            cls.__discriminator_property_name +
            ", mapping: " +
            json.dumps(cls.__discriminator_value_class_map)
        )
